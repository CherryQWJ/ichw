#!/usr/bin/env python3

"""wcount.py: count words from an Internet file.

__author__ = "QiuWeiJie"
__pkuid__  = "1800011802"
__email__  = "1800011802@pku.edu.cn"
"""

import sys
import re
import urllib
from urllib.request import Request,urlopen
from urllib.error import URLError


def wcount(lines, topn):
    """count words from lines of text string, then sort by their counts
    in reverse order, output the topn (word count), each in one line. 
    """
    l = re.split('[.,:-^(){}?"\n\r!;\' /&#*@_]',lines)#将lines里的单词分隔，放入列表l
    statistics = {}
    for i in  l:
        if i not in statistics:
            statistics[i] = 1
        else:
            statistics[i] = statistics[i] + 1 #用字典统计单词出现的次数
    lis = sorted(statistics.items(),key = lambda x:x[1],reverse = True) #将单词出现的次数由大到小排序
    if topn > len(lis):#超出单词种类数，输出全部结果
        dic = dict(lis[1:]) 
    else:      #否则输出想要的个数
        dic = dict(lis[1:topn+1])
    for k in dic:
        print(str(k) + " " + str(dic[k]))  #将字典以一列key，一列对应的value的形式输出
    pass

if __name__ == '__main__':

    if  len(sys.argv) == 1:   #只传给py文件名称，无内容
        print('Usage: {} url [topn]'.format(sys.argv[0]))
        print('  url: URL of the txt file to analyze ')
        print('  topn: how many (words count) to output. If not given, will output top 10 words')
        sys.exit(1)
    else:
        req = Request(sys.argv[1])
        try: 
            response = urlopen(req)
        except URLError as e:     #捕获异常
            if hasattr(e,"code"):
                print (e.code)
            if hasattr(e,"reason"):
                print (e.reason)
        else:
            netaddress = sys.argv[1]   #提取网址
            doc = urlopen(netaddress).read()  #获取网页内容
            m = doc.decode('utf-8') #decode解码 将doc由bytes转化为str类型进行操作
            n = m.lower()       #将文章中的单词全部转化为小写字母
            if len(sys.argv) == 2:  #如果没有输入topn数的话则输出前10个频率最高的词
                wcount(n,10)
            else:
                wcount(n,sys.argv[2])

    sys.exit(1)
    
